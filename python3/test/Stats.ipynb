{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc0db89d",
   "metadata": {},
   "source": [
    "Ce notebook permet de tester les résultats d'un modèle. On utilise deux indices : la RMSE et le SSIM.\n",
    "Il faut bien sûr comparer les résultats entre deux modèles avec la même scène pour que les résultats soient porteurs de sens.\n",
    "\n",
    "Le SSIM (Structure Similary Index) est un flottant dans [-1;1]. Plus il est élevé, plus les images sont similaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1082e02c-d2fa-42f1-b32c-4bda3af29ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beaed971cf9841e391b65c09858e61c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='C', description='model'), Checkbox(value=True, description='directly_inside_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import path\n",
    "import stats\n",
    "import skimage.metrics\n",
    "import numpy as np\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "\n",
    "def gen_mesures(truth, inferred):\n",
    "    \"\"\"\n",
    "    On peut personaliser les mesures que l'on souhaite.\n",
    "    Cette fonction doit retourner un dictionnaire, et pour chaque clé un qui contient le score pour cette mesure.\n",
    "    \n",
    "    Args:\n",
    "        truth (numpy.ndarray): L'image de la profondeur vérité terrain\n",
    "        inferred (numpy.ndarray): L'image de la profondeur inferée\n",
    "\n",
    "    Returns:\n",
    "        Le dictionnaire qui contient les mesures.\n",
    "    \"\"\"\n",
    "    \n",
    "    ssim, diff_ssim = skimage.metrics.structural_similarity(truth, inferred, full=True)\n",
    "    rmse = np.sqrt(np.mean((truth - inferred) ** 2))\n",
    "    \n",
    "    return {\n",
    "        \"ssim\": ssim,\n",
    "        \"rmse\": rmse\n",
    "    }\n",
    "\n",
    "def on_path_changed(dataset_path):\n",
    "    paths = path.load_dataset_paths(dataset_path)\n",
    "    df = stats.compute_dataset_stats(paths, gen_mesures)\n",
    "    display(df)\n",
    "    \n",
    "    stats_df_data = {\"mesure\": [], \"moyenne\": [], \"ecart-type\": []}\n",
    "    for mesure in [\"ssim\", \"rmse\"]:\n",
    "        stats_df_data[\"mesure\"].append(mesure)\n",
    "        stats_df_data[\"moyenne\"].append(df[mesure].mean())\n",
    "        stats_df_data[\"ecart-type\"].append(df[mesure].std())\n",
    "    \n",
    "    display(pd.DataFrame(stats_df_data))\n",
    "\n",
    "@interact(model='C', directly_inside_dataset=True)\n",
    "def on_path_changed_interact(model, directly_inside_dataset):\n",
    "    \n",
    "    if directly_inside_dataset:\n",
    "        on_path_changed(f\"/scratch_p/rafrantz/revery/hf6ag69kr0jdf8ycuw6pf8/\")\n",
    "    else:\n",
    "        on_path_changed(f\"/scratch_p/rafrantz/tf_model_revery_romeo_{model}/tests\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "96620b6de66572b01010b63631958ab83afe846e3d0e21d2183061451720a609"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
